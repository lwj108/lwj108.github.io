---
layout:     post
title:      整理kafka实现思路
subtitle:   记一次kafka消息实际操作记录
date:       2019-07-10
author:     lwj108
header-img: img/post-bg-keybord.jpg
catalog: true
tags:
    - java
    - kafka
---
## 消息结构（生产者微服务+消费者微服务）
kafka的消息实现由Producer生产消息，Consumer消费消息构成。

### 生产者流程
Producer生产消息采用推（push）模式发布到Broker（kafka服务器）,每条消息都被追加（append）到Partition（分区）中，属于顺序写磁盘（顺序写磁盘效率比随机写内存要高，保障kafka吞吐率）。

#### producer写入消息流程如下
[![Z67PIS.png](https://s2.ax1x.com/2019/07/10/Z67PIS.png)](https://imgchr.com/i/Z67PIS)

### 消费者流程
Consumer采用拉（pull）模式，由消费者自己记录消费状态，每个消费者互相独立地顺序读取每个分区的消息。消费者通过控制偏移量（offset）可以任意的顺序消费消息。比如，消费者可以重置到旧的偏移量，重新处理之前已经消费过的消息；或者直接跳到最近的位置，从当前的时刻开始消费。 


#### 消息消费不会立即删除
在某些消息系统中，消息被消费后立即删除。而Kafka的做法是生产者发布的所有消息会一致保存在Kafka集群中，不管消息有没有被消费。用户可以通过设置保留时间来清理过期的数据，比如，设置保留策略为两天。那么，在消息发布之后，它可以被不同的消费者消费，在两天之后，过期的消息就会自动清理掉。

## 具体实现步骤
* 需求：在实际中一条batch消息需要分发非常多的人，原始通过数据库去操作读写量太大，效率也低下。而通过消息队列去实现还可以省去并发（kafka服务的吞吐量完全足够）；
* 生产者：通过Schedule定时解析batch中需要分发每条消息（实现1->多）推送到kafka服务，记录batch推送状态
* 消费者：通过KafkaListener拉取kafka服务中的消息（实现多->多），数据量大的时候多个消费者分流。记录消息消费状态
* 重发：对于batch推送失败的进行重发kafka，对于消息消费失败的进行重发kafka。